<launch>

  <arg name="audio_org" default="/nao_robot/naoqi_driver/audio" />
  <arg name="audio_topic" default="/audio" />
  <arg name="n_channel" default="1" />
  <arg name="depth" default="16" />
  <arg name="sample_rate" default="48000" />
  <arg name="engine" default="Google" />
  <arg name="language" default="ja-JP" />
  <arg name="continuous" default="true" />
  <arg name="dynamic_energy_threshold" default="false" />
  <arg name="energy_threshold" default="50" />
  
  <node pkg="naoqi_speech_recognition" 
	name="publish_audiodata" 
	type="publish_audiodata.py" 
	output="screen">

    <rosparam subst_value="true">
      audio_org: $(arg audio_org)
    </rosparam>
  </node>

  <node name="speech_recognition"
        pkg="ros_speech_recognition" 
	type="speech_recognition_node.py"
        respawn="true"
        output="screen">
    <rosparam subst_value="true">
      audio_topic: $(arg audio_topic)
      n_channel: $(arg n_channel)
      depth: $(arg depth)
      sample_rate: $(arg sample_rate)
      engine: $(arg engine)
      language: $(arg language)
      continuous: $(arg continuous)
      dynamic_energy_threshold: $(arg dynamic_energy_threshold)
      energy_threshold: $(arg energy_threshold)
    </rosparam>
  </node>

</launch>
